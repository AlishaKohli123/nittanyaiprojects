{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmVuyp9D6K19NhKAqqpGP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlishaKohli123/nittanyaiprojects/blob/main/Cat_Dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc2GYRZzKyzh",
        "outputId": "97fcc437-6907-4835-e742-6087378eaff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-15 03:53:40--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.96.207, 108.177.119.207, 108.177.127.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.96.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  27.4MB/s    in 2.4s    \n",
            "\n",
            "2024-11-15 03:53:42 (27.4 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "source": [
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "\n",
        "cats_dir = os.path.join(train_dir + \"/cats\")\n",
        "dogs_dir = os.path.join(train_dir + \"/dogs\")\n",
        "i = 0\n",
        "while i < 3:\n",
        "  if i % 2 == 0:\n",
        "    im = Image.open(os.path.join(cats_dir, os.listdir(cats_dir)[i])).convert(\"RGB\")\n",
        "    # Resize the image\n",
        "    im_resized = im.resize((128,128)) # Resize to a desired size, e.g., 128x128\n",
        "\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    im = Image.open(os.path.join(dogs_dir, os.listdir(dogs_dir)[i])).convert(\"RGB\")\n",
        "    # Resize the image\n",
        "    im_resized = im.resize((128,128)) # Resize to a desired size, e.g., 128x128\n",
        "\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(0)\n",
        "  i += 1"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zgVA8QI14K4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 1: Define a Custom Dataset Class\n",
        "class CatsDogsDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.cats_dir = os.path.join(img_dir, \"cats\")\n",
        "        self.dogs_dir = os.path.join(img_dir, \"dogs\")\n",
        "        self.cat_images = os.listdir(self.cats_dir)\n",
        "        self.dog_images = os.listdir(self.dogs_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cat_images) + len(self.dog_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.cat_images):\n",
        "            img_path = os.path.join(self.cats_dir, self.cat_images[idx])\n",
        "            label = 0  # Cat\n",
        "        else:\n",
        "            img_path = os.path.join(self.dogs_dir, self.dog_images[idx - len(self.cat_images)])\n",
        "            label = 1  # Dog\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Step 2: Define the transformations and load the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Replace 'path_to_train_data' with the actual path to your training data\n",
        "train_dir = '/tmp/cats_and_dogs_filtered/train' # This is the path from where data was extracted in previous cell.\n",
        "dataset = CatsDogsDataset(train_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 3: Load and Modify ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 1),  # Binary classification\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# Step 4: Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 5: Train the Model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.float().to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.view(-1), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Step 6: Prediction on New Images\n",
        "def predict_image(img_path):\n",
        "    img = Image.open(img).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "        prediction = torch.sigmoid(output).item()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Lju8gk9vzk",
        "outputId": "dc2fb03b-d03a-4920-f189-76dab93a5118"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 127MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4327\n"
          ]
        }
      ]
    }
  ]
}